---
sidebar_position: 1
---

# 局限性

虽然GPT-4很强大，但还是有不少局限性。首先，GPT-4仍然是生成模型，生成模型的一个通病就是它生成的东西有可能是不准确的，它会编造一些事实，以及一些推理仍然会出错。不同于搜索引擎，语言模型生成的东西还不是完全可靠的，比如有的同学让ChatGPT写论文，它的参考文献很多都是编造的。所以大家在一些领域，尤其是敏感领域中要使用ChatGPT的话，要谨慎使用。

虽然存在这些问题，GPT-4在OpenAI的内部有专门的对抗训练，相比GPT-3.5它的安全性可靠性有40%以上的提升。

除了上述问题之外，GPT-4还会有一些偏见问题，以及缺少2021年9月之后的知识（训练数据截止到2021年）。来指令微调和人类反馈的强化学习中也会使用一些新的数据，所以2021年之后的部分问题模型也能回答正确。GPT-4虽然在很多的测试中很牛批，但会犯一些很简单的逻辑错误，ChatGPT很容易上当受骗，比如问他1+1等于几，然后和它说1+1等于3，重复多次后，ChatGPT会上当认为自己错了。

